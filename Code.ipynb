{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84192\n",
      "68424\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/trainPosNeg.csv')\n",
    "\n",
    "# Keeping only the neccessary columns\n",
    "data = data[['text','sentiment']]\n",
    "\n",
    "print(data[ data['sentiment'] == 'Positive'].size)\n",
    "print(data[ data['sentiment'] == 'Negative'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "    data['text'] = data['text'].apply((lambda x: re.sub(\"[^a-zA-z0-9'\\s]\",'',x)))\n",
    "except AttributeError:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in data.iterrows():\n",
    "    try:\n",
    "        row[0] = row[0].replace('rt',' ')\n",
    "    except:\n",
    "        print('error '+ str(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data['text'].values\n",
    "\n",
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(X1)\n",
    "X = tokenizer.texts_to_sequences(X1)\n",
    "X = pad_sequences(X)\n",
    "Y = []\n",
    "for y in data['sentiment'].values:\n",
    "    if y == 'Positive':\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length = 49\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "print('input length = '+str(X.shape[1]))\n",
    "intputLen = X.shape[1]\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51126, 49) 51126\n",
      "(25182, 49) 25182\n",
      "Train on 51126 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "51126/51126 [==============================] - 116s 2ms/step - loss: 0.3826 - acc: 0.8256 - val_loss: 0.2966 - val_acc: 0.8853\n",
      "Epoch 2/10\n",
      "51126/51126 [==============================] - 117s 2ms/step - loss: 0.1963 - acc: 0.9246 - val_loss: 0.2716 - val_acc: 0.9027\n",
      "Epoch 3/10\n",
      "51126/51126 [==============================] - 113s 2ms/step - loss: 0.1304 - acc: 0.9492 - val_loss: 0.2802 - val_acc: 0.9080\n",
      "Epoch 4/10\n",
      "51126/51126 [==============================] - 114s 2ms/step - loss: 0.0948 - acc: 0.9641 - val_loss: 0.2853 - val_acc: 0.9060\n",
      "Epoch 5/10\n",
      "51126/51126 [==============================] - 114s 2ms/step - loss: 0.0744 - acc: 0.9711 - val_loss: 0.3251 - val_acc: 0.9093\n",
      "Epoch 6/10\n",
      "51126/51126 [==============================] - 114s 2ms/step - loss: 0.0607 - acc: 0.9752 - val_loss: 0.3758 - val_acc: 0.9160\n",
      "Epoch 7/10\n",
      "51126/51126 [==============================] - 114s 2ms/step - loss: 0.0512 - acc: 0.9789 - val_loss: 0.3598 - val_acc: 0.9147\n",
      "Epoch 8/10\n",
      "51126/51126 [==============================] - 115s 2ms/step - loss: 0.0428 - acc: 0.9815 - val_loss: 0.4253 - val_acc: 0.9093\n",
      "Epoch 9/10\n",
      "51126/51126 [==============================] - 115s 2ms/step - loss: 0.0378 - acc: 0.9841 - val_loss: 0.4271 - val_acc: 0.9100\n",
      "Epoch 10/10\n",
      "51126/51126 [==============================] - 114s 2ms/step - loss: 0.0337 - acc: 0.9858 - val_loss: 0.4491 - val_acc: 0.9113\n",
      "score: 0.50\n",
      "acc: 0.91\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,len(Y_train))\n",
    "print(X_test.shape,len(Y_test))\n",
    "\n",
    "batch_size = 32\n",
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = [Y_test[-validation_size:]]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = [Y_test[:-validation_size]]\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1,validation_data=(X_validate, Y_validate))\n",
    "\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseSentiment(data):\n",
    "    twt = [data]\n",
    "    #vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "    twt = tokenizer.texts_to_sequences(twt)\n",
    "    #padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "    twt = pad_sequences(twt, maxlen=intputLen, dtype='int32', value=0)\n",
    "    sentiment = model.predict(twt,batch_size=1,verbose = 2)\n",
    "    if(sentiment[0] < 0.5):\n",
    "        return \"Negative with \"+ \"{0:.2f}\".format((1 - sentiment[0][0]) * 100)+ \"% Confidence.\"\n",
    "    else:\n",
    "        return \"Positive with \"+\"{0:.2f}\".format(sentiment[0][0] * 100)+\"% Confidence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive with 100.00% Confidence.\n"
     ]
    }
   ],
   "source": [
    "print(analyseSentiment(\"You are great.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('sentiment_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
